import dbm.dumb
import json
import logging
import shelve
from datetime import date, timedelta
from enum import Enum, auto
from itertools import cycle
from random import random, randint, shuffle
from time import sleep
from typing import Final

import requests
from selenium.webdriver.common.by import By

from src.browser import Browser
from src.utils import CONFIG, makeRequestsSession, getProjectRoot, active_sleep
from main import check_for_stop_signal


class RetriesStrategy(Enum):
	"""
	method to use when retrying
	"""

	EXPONENTIAL = auto()
	"""
	an exponentially increasing `base_delay_in_seconds` between attempts
	"""
	CONSTANT = auto()
	"""
	the default; a constant `base_delay_in_seconds` between attempts
	"""


class Searches:
	maxRetries: Final[int] = CONFIG.retries.max
	"""
	the max amount of retries to attempt
	"""
	baseDelay: Final[float] = CONFIG.get("retries.base_delay_in_seconds")
	"""
	how many seconds to delay
	"""
	# retriesStrategy = Final[  # todo Figure why doesn't work with equality below
	retriesStrategy = RetriesStrategy[CONFIG.retries.strategy]

	def __init__(self, browser: Browser):
		self.browser = browser
		self.webdriver = browser.webdriver

		dumbDbm = dbm.dumb.open((getProjectRoot() / "google_trends").__str__())
		self.googleTrendsShelf: shelve.Shelf = shelve.Shelf(dumbDbm)

	def __enter__(self):
		return self

	def __exit__(self, exc_type, exc_val, exc_tb):
		self.googleTrendsShelf.__exit__(None, None, None)

	def getGoogleTrends(self, words_count: int) -> list[str]:
		"""
		Retrieves Google Trends search terms via the new API (last 48 hours).
		"""
		logging.debug("Starting Google Trends fetch (last 48 hours)...")
		search_terms: list[str] = []
		session = makeRequestsSession()
		
		url = "https://trends.google.com/_/TrendsUi/data/batchexecute"
		payload = f'f.req=[[[i0OFE,"[null, null, \\"{self.browser.localeGeo}\\", 0, null, 48]"]]]'
		headers = {"Content-Type": "application/x-www-form-urlencoded;charset=UTF-8"}
		
		logging.debug(f"Sending POST request to {url}")
		try:
			response = session.post(url, headers=headers, data=payload)
			response.raise_for_status()
			logging.debug("Response received from Google Trends API")
		except requests.RequestException as e:
			logging.error(f"Error fetching Google Trends: {e}")
			return []

		trends_data = self.extract_json_from_response(response.text)
		if not trends_data:
			logging.error("Failed to extract JSON from Google Trends response")
			return []
	
		logging.debug("JSON successfully extracted. Processing root terms...")
	
		# Process only the first element in each item
		root_terms = []
		for item in trends_data:
			try:
				topic = item[0]
				root_terms.append(topic)
			except Exception as e:
				logging.warning(f"Error processing an item: {e}")
				continue
	
		logging.debug(f"Extracted {len(root_terms)} root trend entries")
	
		# Convert to lowercase and remove duplicates
		search_terms = list(set(term.lower() for term in root_terms))
		logging.debug(f"Found {len(search_terms)} unique search terms")
	
		if words_count < len(search_terms):
			logging.debug(f"Limiting search terms to {words_count} items")
			search_terms = search_terms[:words_count]
	
		logging.debug("Google Trends fetch complete")
		return search_terms

	def extract_json_from_response(self, text: str):
		"""
		Extracts the nested JSON object from the API response.
		"""
		logging.debug("Extracting JSON from API response")
		for line in text.splitlines():
			trimmed = line.strip()
			if trimmed.startswith('[') and trimmed.endswith(']'):
				try:
					intermediate = json.loads(trimmed)
					data = json.loads(intermediate[0][2])
					logging.debug("JSON extraction successful")
					return data[1]
				except Exception as e:
					logging.warning(f"Error parsing JSON: {e}")
					continue
		logging.error("No valid JSON found in response")
		return None

	def getRelatedTerms(self, term: str) -> list[str]:
		# Function to retrieve related terms from Bing API
		relatedTerms: list[str] = (
			makeRequestsSession()
			.get(
				f"https://api.bing.com/osjson.aspx?query={term}",
				headers={"User-agent": self.browser.userAgent},
			)
			.json()[1]
		)  # todo Wrap if failed, or assert response?
		if not relatedTerms:
			return [term]
		return relatedTerms

	def bingSearches(self) -> None:
		# Function to perform Bing searches
		logging.info(
			f"[BING] Starting {self.browser.browserType.capitalize()} Edge Bing searches..."
		)

		self.browser.utils.goToSearch()

		while True:
			# Check for stop signal
			try:
				if check_for_stop_signal():
					logging.info("Stop signal detected during Bing searches, breaking early")
					break
			except (ImportError, AttributeError):
				pass
				
			desktopAndMobileRemaining = self.browser.getRemainingSearches(
				desktopAndMobile=True
			)
			logging.info(f"[BING] Remaining searches={desktopAndMobileRemaining}")
			if (
				self.browser.browserType == "desktop"
				and desktopAndMobileRemaining.desktop == 0
			) or (
				self.browser.browserType == "mobile"
				and desktopAndMobileRemaining.mobile == 0
			):
				break

			if desktopAndMobileRemaining.getTotal() > len(self.googleTrendsShelf):
				# self.googleTrendsShelf.clear()  # Maybe needed?
				logging.debug(
					f"google_trends before load = {list(self.googleTrendsShelf.items())}"
				)
				trends = self.getGoogleTrends(desktopAndMobileRemaining.getTotal())
				shuffle(trends)
				for trend in trends:
					self.googleTrendsShelf[trend] = None
				logging.debug(
					f"google_trends after load = {list(self.googleTrendsShelf.items())}"
				)

			self.bingSearch()
			del self.googleTrendsShelf[list(self.googleTrendsShelf.keys())[0]]
			sleep(randint(10, 15))

		logging.info(
			f"[BING] Finished {self.browser.browserType.capitalize()} Edge Bing searches !"
		)

	def bingSearch(self) -> None:
		# Function to perform a single Bing search
		pointsBefore = self.browser.utils.getAccountPoints()

		rootTerm = list(self.googleTrendsShelf.keys())[0]
		terms = self.getRelatedTerms(rootTerm)
		logging.debug(f"terms={terms}")
		termsCycle: cycle[str] = cycle(terms)
		baseDelay = Searches.baseDelay
		logging.debug(f"rootTerm={rootTerm}")

		# todo If first 3 searches of day, don't retry since points register differently, will be a bit quicker
		for i in range(self.maxRetries + 1):
			# Check for stop signal
			try:
				if check_for_stop_signal():
					logging.info("Stop signal detected during Bing search, breaking early")
					return
			except (ImportError, AttributeError):
				pass
				
			if i != 0:
				sleepTime: float
				if Searches.retriesStrategy == Searches.retriesStrategy.EXPONENTIAL:
					sleepTime = baseDelay * 2 ** (i - 1)
				elif Searches.retriesStrategy == Searches.retriesStrategy.CONSTANT:
					sleepTime = baseDelay
				else:
					raise AssertionError
				sleepTime += baseDelay * random()  # Add jitter
				logging.debug(
					f"[BING] Search attempt not counted {i}/{Searches.maxRetries}, sleeping {sleepTime}"
					f" seconds..."
				)
				sleep(sleepTime)

			searchbar = self.browser.utils.waitUntilClickable(
				By.ID, "sb_form_q", timeToWait=40
			)
			searchbar.clear()
			term = next(termsCycle)
			logging.debug(f"term={term}")
			sleep(1)
			searchbar.send_keys(term)
			sleep(1)
			searchbar.submit()

			pointsAfter = self.browser.utils.getAccountPoints()
			if pointsBefore < pointsAfter:
				sleep(randint(CONFIG.cooldown.min, CONFIG.cooldown.max))
				return

			# todo
			# if i == (maxRetries / 2):
			#     logging.info("[BING] " + "TIMED OUT GETTING NEW PROXY")
			#     self.webdriver.proxy = self.browser.giveMeProxy()
		logging.error("[BING] Reached max search attempt retries")